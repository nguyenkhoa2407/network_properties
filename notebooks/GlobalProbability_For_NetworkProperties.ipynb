{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import copy\n",
    "import pprint\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/khoanguyen-cp/gmu/network_properties')\n",
    "\n",
    "from models.test_models import ProphecyPaperNetwork, TestModel\n",
    "from models.acasxu_1_1 import Acasxu1_1\n",
    "from models.utils import attach_relu_activation_hook, attach_layer_output_hook, get_layers_info\n",
    "from models.utils import turn_bool_activation_to_int, turn_bool_activation_to_str\n",
    "\n",
    "from algorithms.decision_procedure import MarabouCoreDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd766f4",
   "metadata": {},
   "source": [
    "## 1. Prepare model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf81ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Acasxu1_1()\n",
    "model.load_state_dict(torch.load('../models/acasxu_1_1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0415796",
   "metadata": {},
   "outputs": [],
   "source": [
    "acas_train = np.empty([384221,5],dtype=float)\n",
    "acas_train_labels = np.zeros(384221,dtype=int)\n",
    "\n",
    "def read_inputs_from_file(inputFile):\n",
    "  global acas_train, acas_train_labels, num\n",
    "  with open(inputFile) as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines), \"examples\")\n",
    "    acas_train = np.empty([len(lines),5],dtype=float)\n",
    "    acas_train_labels = np.zeros(len(lines),dtype=int)\n",
    "\n",
    "    for l in range(len(lines)):\n",
    "      # This is to remove the useless 1 at the start of each string. Not sure why that's there.\n",
    "      k = [float(stringIn) for stringIn in lines[l].split(',')] \n",
    "      \n",
    "      # acas_train[l+num] = np.zeros(5,dtype=float) \n",
    "      # we're asuming that everything is 2D for now. The 1 is just to keep numpy happy.\n",
    "      if len(k) > 5:\n",
    "        lab = int(k[5])\n",
    "        #if ((lab == 0) or (lab == 2)):\n",
    "        #  lab = 0\n",
    "        #else:\n",
    "        #  lab = 1\n",
    "        acas_train_labels[l+num] = lab\n",
    "\n",
    "      count = 0\n",
    "      for i in range(0,5):\n",
    "        #print(count)\n",
    "        acas_train[l+num][i] = k[i]\n",
    "        #print(k[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "read_inputs_from_file('../datasets/clusterinACAS_0_shrt.csv')\n",
    "print(acas_train.shape)\n",
    "print(acas_train_labels.shape)\n",
    "print(acas_train[:5])\n",
    "print(acas_train_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(inputs, predicted_labels, true_labels, activation_signature):\n",
    "  data = []\n",
    "  for index, input_data in enumerate(inputs):\n",
    "    data_point = { \n",
    "      \"input\": input_data, \n",
    "      \"true_label\": true_labels[index], \n",
    "      \"predicted_label\": predicted_labels[index].item(),\n",
    "    }\n",
    "    data_point_full_signature = {} \n",
    "    for name, layer_activation in activation_signature.items():\n",
    "      data_point[name] = json.dumps(layer_activation[index])\n",
    "      data_point_full_signature[name] = layer_activation[index]\n",
    "      \n",
    "    data_point['full_signature_str'] = json.dumps(data_point_full_signature)\n",
    "    data.append(data_point)\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "_act_handles, activation_signature = attach_relu_activation_hook(model)  \n",
    "outputs = model(torch.tensor(acas_train, dtype=torch.float32))\n",
    "predicted_labels = torch.argmin(outputs, dim=1)\n",
    "activation_signature = turn_bool_activation_to_int(activation_signature, to_list=True)\n",
    "df = create_df(acas_train, predicted_labels, acas_train_labels, activation_signature)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2158d9d",
   "metadata": {},
   "source": [
    "## 2. Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_activation_counts(model, sample):\n",
    "  _act_handles, activation_signature = attach_relu_activation_hook(model)  \n",
    "  X = torch.tensor(sample, dtype=torch.float)\n",
    "  _logits = model(X)\n",
    "  \n",
    "  activation_signature = turn_bool_activation_to_int(activation_signature)\n",
    "  for layer_name, activations in activation_signature.items():\n",
    "    activation_signature[layer_name] = np.zeros_like(activations[0])\n",
    "    \n",
    "  return activation_signature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e28376",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = 0\n",
    "\n",
    "# get all data points with predicted class y\n",
    "class_df = df[df['predicted_label'] == y_class]\n",
    "\n",
    "ranges = []\n",
    "for i in range(5):\n",
    "  min_val = class_df['input'].apply(lambda x: x[i]).min()\n",
    "  max_val = class_df['input'].apply(lambda x: x[i]).max()\n",
    "  ranges.append([min_val, max_val])\n",
    "\n",
    "# initialize the activation counts dictionary using the activation signature dictionary\n",
    "# cus they should have the same structure \n",
    "activation_counts = initialize_activation_counts(model, [[0.62, 0.1, 0.2, 0.47, -0.48]])  \n",
    "\n",
    "# calculate activation probability of each neuron in the network\n",
    "for index, row in class_df.iterrows():\n",
    "  full_signature = json.loads(row['full_signature_str'])\n",
    "  for layer, activation in full_signature.items():\n",
    "    # update activation count\n",
    "    activation_counts[layer] += np.array(activation)\n",
    "    \n",
    "activation_probabilities = {}\n",
    "for layer, neuron_act_counts in activation_counts.items():\n",
    "  activation_probabilities[layer] = neuron_act_counts/len(class_df)\n",
    "    \n",
    "np.set_printoptions(formatter={'float': '{: 0.8f}'.format})\n",
    "activation_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f31557",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate = activation_probabilities.copy()\n",
    "for layer, activation_probs in candidate.items():\n",
    "  new_activation = [\n",
    "    \"ON\" if prob == 1 else (\"OFF\" if prob == 0 else \"--\")\n",
    "    for prob in activation_probs\n",
    "  ]\n",
    "  candidate[layer] = new_activation\n",
    "print(candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "specification_for_classes = {\n",
    "  0: [(np.array([[-1, 1, 0, 0, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 0, 1, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 0, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  1: [(np.array([[1, -1, 0, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 0, 1, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 0, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  2: [(np.array([[1, 0, -1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, 1, -1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, -1, 1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, -1, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  3: [(np.array([[1, 0, 0, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 1, 0, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, 1, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, 0, -1, 1]]), np.array([0]))],\n",
    "  \n",
    "  4: [(np.array([[1, 0, 0, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 1, 0, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 0, 1, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 0, 0, 1, -1]]), np.array([0]))],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d07e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = MarabouCoreDP()\n",
    "dp.solve(candidate, model, ranges, specification_for_classes[y_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007d5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
