{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4727311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import copy\n",
    "import pprint\n",
    "import json\n",
    "import time\n",
    "\n",
    "from onnx2pytorch import ConvertModel\n",
    "from torch import nn\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('..')\n",
    "\n",
    "from algorithms.iterative_relaxation import IterativeRelaxation\n",
    "from algorithms.decision_procedure import MarabouCoreDP\n",
    "from algorithms.decision_tree import DecisionTree\n",
    "\n",
    "from models.test_models import ProphecyPaperNetwork, TestModel\n",
    "from models.acasxu_1_1 import Acasxu1_1\n",
    "from models.utils import attach_relu_activation_hook, attach_layer_output_hook, get_layers_info\n",
    "from models.utils import turn_bool_activation_to_int, turn_bool_activation_to_str\n",
    "\n",
    "\n",
    "torch.set_printoptions(precision=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Acasxu1_1()\n",
    "model.load_state_dict(torch.load('../models/acasxu_1_1.pt'))\n",
    "_act_handles, activation_signature = attach_relu_activation_hook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from properties.read_vnnlib import read_vnnlib\n",
    "from pathlib import Path\n",
    "vnnlib_path = Path(\"../properties/prop_1.vnnlib\") # acasxu\n",
    "# vnnlib_path = Path(\"./network_properties/prop_0_0.03.vnnlib\") # MNIST\n",
    "\n",
    "input_ranges, specifications = read_vnnlib(vnnlib_path)[0]\n",
    "print(input_ranges)\n",
    "print(specifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8999aaed",
   "metadata": {},
   "source": [
    "## Test input property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_act_handles, activation_signature = attach_relu_activation_hook(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bda507",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [[0.62, 0.1, 0.2, 0.47, -0.48]]\n",
    "X = torch.tensor(input_data, dtype=torch.float)\n",
    "_logits = model(X)\n",
    "\n",
    "activation_signature = turn_bool_activation_to_str(activation_signature)\n",
    "for layer_name, activations in activation_signature.items():\n",
    "  activation_signature[layer_name] = activations[0]\n",
    "  \n",
    "print(activation_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf381f",
   "metadata": {},
   "source": [
    "## 0. Prepare ACASXU dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747919a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/safednn-nasa/prophecy_DNN/master/clusterinACAS_0_short.csv -O ./datasets/clusterinACAS_0_shrt.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658717cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acas_train = np.empty([384221,5],dtype=float)\n",
    "acas_train_labels = np.zeros(384221,dtype=int)\n",
    "\n",
    "def read_inputs_from_file(inputFile):\n",
    "  global acas_train, acas_train_labels, num\n",
    "  with open(inputFile) as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines), \"examples\")\n",
    "    acas_train = np.empty([len(lines),5],dtype=float)\n",
    "    acas_train_labels = np.zeros(len(lines),dtype=int)\n",
    "\n",
    "    for l in range(len(lines)):\n",
    "      # This is to remove the useless 1 at the start of each string. Not sure why that's there.\n",
    "      k = [float(stringIn) for stringIn in lines[l].split(',')] \n",
    "      \n",
    "      # acas_train[l+num] = np.zeros(5,dtype=float) \n",
    "      # we're asuming that everything is 2D for now. The 1 is just to keep numpy happy.\n",
    "      if len(k) > 5:\n",
    "        lab = int(k[5])\n",
    "        #if ((lab == 0) or (lab == 2)):\n",
    "        #  lab = 0\n",
    "        #else:\n",
    "        #  lab = 1\n",
    "        acas_train_labels[l+num] = lab\n",
    "\n",
    "      count = 0\n",
    "      for i in range(0,5):\n",
    "        #print(count)\n",
    "        acas_train[l+num][i] = k[i]\n",
    "        #print(k[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25958f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "read_inputs_from_file('../datasets/clusterinACAS_0_shrt.csv')\n",
    "print(acas_train.shape)\n",
    "print(acas_train_labels.shape)\n",
    "acas_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c245d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(inputs, predicted_labels, true_labels, activation_signature):\n",
    "  data = []\n",
    "  for index, input_data in enumerate(inputs):\n",
    "    data_point = { \n",
    "      \"input\": input_data, \n",
    "      \"true_label\": true_labels[index], \n",
    "      \"predicted_label\": predicted_labels[index].item(),\n",
    "    }\n",
    "    data_point_full_signature = {} \n",
    "    for name, layer_activation in activation_signature.items():\n",
    "      data_point[name] = json.dumps(layer_activation[index])\n",
    "      data_point_full_signature[name] = layer_activation[index]\n",
    "      \n",
    "    data_point['full_signature'] = json.dumps(data_point_full_signature)\n",
    "    data.append(data_point)\n",
    "\n",
    "  return pd.DataFrame(data)\n",
    "\n",
    "outputs = model(torch.tensor(acas_train, dtype=torch.float32))\n",
    "predicted_labels = torch.argmin(outputs, dim=1)\n",
    "activation_signature = turn_bool_activation_to_int(activation_signature, to_list=True)\n",
    "df = create_df(acas_train, predicted_labels, acas_train_labels, activation_signature)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test accuracy\n",
    "len(df[df[\"predicted_label\"] == df['true_label']]) / (len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c30c16",
   "metadata": {},
   "source": [
    "## 1. Input properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4592db40",
   "metadata": {},
   "source": [
    "### 1.1 With DP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaab744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare candidate input property for each class \n",
    "# For example: specification for output = class 0, meaning constraints for NOT class 0\n",
    "# since the result is argmin, this would mean we'll encode constraints for y0 NOT being the min value\n",
    "# i.e. y1 <= y0 or y2 <= y0 or y3 <= y0 or y4 <= y0\n",
    "specification_for_classes = {\n",
    "  0: [(np.array([[-1, 1, 0, 0, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 0, 1, 0]]), np.array([0])),\n",
    "      (np.array([[-1, 0, 0, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  1: [(np.array([[1, -1, 0, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 0, 1, 0]]), np.array([0])),\n",
    "      (np.array([[0, -1, 0, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  2: [(np.array([[1, 0, -1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, 1, -1, 0, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, -1, 1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, -1, 0, 1]]), np.array([0]))],\n",
    "  \n",
    "  3: [(np.array([[1, 0, 0, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 1, 0, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, 1, -1, 0]]), np.array([0])),\n",
    "      (np.array([[0, 0, 0, -1, 1]]), np.array([0]))],\n",
    "  \n",
    "  4: [(np.array([[1, 0, 0, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 1, 0, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 0, 1, 0, -1]]), np.array([0])),\n",
    "      (np.array([[0, 0, 0, 1, -1]]), np.array([0]))],\n",
    "}\n",
    "\n",
    "candidates = {}\n",
    "input_ranges = {}\n",
    "samples = {}\n",
    "\n",
    "for y_class in range(5):\n",
    "  # Group the DataFrame by 'full_signature' column and get the group sizes\n",
    "  # Get the signature with the highest support\n",
    "  class_df = df[df['predicted_label'] == y_class]\n",
    "  group_sizes = class_df.groupby('full_signature').size()\n",
    "  activation_with_max_support = group_sizes.idxmax()\n",
    "  activation_pattern = json.loads(activation_with_max_support)\n",
    "  \n",
    "  # Turn activation from 0 and 1 to ON and OFF to match DP's format\n",
    "  for layer, activation in activation_pattern.items():\n",
    "    activation_pattern[layer] = [\"ON\" if val == 1 else \"OFF\" for val in activation]\n",
    "  candidates[y_class] = activation_pattern\n",
    "  \n",
    "  # Find input ranges for the candidate property\n",
    "  ranges = []\n",
    "  support_df = class_df[class_df['full_signature'] == activation_with_max_support]\n",
    "  for i in range(5):\n",
    "    min_val = support_df['input'].apply(lambda x: x[i]).min()\n",
    "    max_val = support_df['input'].apply(lambda x: x[i]).max()\n",
    "    ranges.append([min_val, max_val])\n",
    "  input_ranges[y_class] = ranges\n",
    "  \n",
    "  # Sample a data point from support\n",
    "  sample_row = support_df.sample()\n",
    "  assert str(sample_row.get('full_signature').item()) == str(activation_with_max_support)\n",
    "  samples[y_class] = sample_row.get('input').item()\n",
    "  \n",
    "# pprint.pprint(\"CANDIDATE PROPERTIES:\")\n",
    "# pprint.pprint(candidates)\n",
    "\n",
    "# pprint.pprint(\"INPUT RANGES:\")\n",
    "# pprint.pprint(input_ranges)\n",
    "\n",
    "# pprint.pprint(\"SAMPLES:\")\n",
    "# pprint.pprint(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3302a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823da396",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e08e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = MarabouCoreDP()\n",
    "for y_class in range(5):\n",
    "  activation_pattern = candidates[y_class]\n",
    "  x_ranges = input_ranges[y_class]\n",
    "  specification = specification_for_classes[y_class]\n",
    "  status, counter_example, _, _ = dp.solve(activation_pattern, model, x_ranges, specification)\n",
    "  if status == 'unsat':\n",
    "    print(f\"{activation_pattern} is an input property for class {y_class}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2b41c",
   "metadata": {},
   "source": [
    "### 1.2 With Iterative Relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227df793",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_relaxation = IterativeRelaxation()\n",
    "\n",
    "for y_class in range(5):\n",
    "  x_ranges = input_ranges[y_class]\n",
    "  input_sample = np.array([samples[y_class]])\n",
    "  specification = specification_for_classes[y_class]\n",
    "  input_property = iterative_relaxation.call(model, input_sample, x_ranges, specification)\n",
    "  print(f\"input property for class {y_class}: {input_property}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc856c0",
   "metadata": {},
   "source": [
    "## 2. Layer patterns as interpolants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724bab6",
   "metadata": {},
   "source": [
    "### 2.1 Find candidates with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c79d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu_layers = ['relu0', 'relu1', 'relu2', 'relu3', 'relu4']\n",
    "# labels = [0,1,2,3,4]\n",
    "# for name, module in list(model.named_modules()):\n",
    "#   if isinstance(module, torch.nn.ReLU):\n",
    "#     relu_layers.append(name)\n",
    "# relu_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ec7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer_name in relu_layers: \n",
    "#   for chosen_label in [0,1,2,3,4]:\n",
    "#     df['satisfies_postcon'] = np.where(df['predicted_label'] == chosen_label, 1, -1)\n",
    "#     decision_tree = DecisionTree(df, X_col=layer_name, Y_col=\"satisfies_postcon\")\n",
    "#     leaves_with_activation_pattern = decision_tree.get_potential_layer_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['satisfies_postcon'] = np.where(df['predicted_label'] == 3, 1, -1)\n",
    "# decision_tree = DecisionTree(df, X_col='relu4', Y_col=\"satisfies_postcon\")\n",
    "# leaves_with_activation_pattern = decision_tree.get_potential_layer_properties()\n",
    "\n",
    "# num_of_patterns = len(leaves_with_activation_pattern)\n",
    "# print(f\"num_of_patterns: {num_of_patterns}\")\n",
    "\n",
    "# total_support = sum(candidate['support'] for candidate in leaves_with_activation_pattern)\n",
    "# print(f\"total_support: {total_support}\")\n",
    "\n",
    "# top_5_supports = [candidate['support'] for candidate in leaves_with_activation_pattern[:5]]\n",
    "# print(f\"top_5_supports: {top_5_supports}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
